Analyze this portion of the codebase and extract key information about functionality, dependencies, and features:

**25-27: dCas9**

**28-30: BE4alone**

**31-33: ABE8alone**

**34-39: Unedited**

```python
df_trimmed = raw_df1_T.iloc[:, :100]
df_trimmed
```

```python
mechanisms = {
    "BE4": ["GSM6745599", "GSM6745600", "GSM6745601", "GSM6745611", "GSM6745612", "GSM6745613"],
    "ABE8": ["GSM6745602", "GSM6745603", "GSM6745604", "GSM6745614", "GSM6745615", "GSM6745616"],
    "Cas9": ["GSM6745605", "GSM6745606", "GSM6745607", "GSM6745617", "GSM6745618", "GSM6745619"],
    "Utelectro": ["GSM6745609", "GSM6745610", "GSM6745620", "GSM6745621", "GSM6745622"],
    "dCas9": ["GSM6745623", "GSM6745624", "GSM6745625"],
    "BE4alone": ["GSM6745626", "GSM6745627", "GSM6745628"],
    "ABE8alone": ["GSM6745629", "GSM6745630", "GSM6745631"],
    "UT": ["GSM6745632", "GSM6745633", "GSM6745634", "GSM6745635", "GSM6745636", "GSM6745637"]
}
#GSM6745608 is missing from Utelectro
```

```python
df_be4 = df_trimmed.loc[mechanisms["BE4"]]
df_abe8 = df_trimmed.loc[mechanisms["ABE8"]]
df_cas9 = df_trimmed.loc[mechanisms["Cas9"]]
df_utelectro = df_trimmed.loc[mechanisms["Utelectro"]]
df_dcas9 = df_trimmed.loc[mechanisms["dCas9"]]
df_be4alone = df_trimmed.loc[mechanisms["BE4alone"]]
df_abe8alone = df_trimmed.loc[mechanisms["ABE8alone"]]

df_edited = df_trimmed.loc[mechanisms["BE4"]+mechanisms["ABE8"]+mechanisms["Cas9"]+mechanisms["Utelectro"]+mechanisms["dCas9"]+mechanisms["BE4alone"]+mechanisms["ABE8alone"]]
df_ut = df_trimmed.loc[mechanisms["UT"]]

```

```python
be4_median = df_be4.median()
abe8_median = df_abe8.median()
cas9_median = df_cas9.median()
utelectro_median = df_utelectro.median()
dcas9_median = df_dcas9.median()
be4alone_median = df_be4alone.median()
abe8alone_median = df_abe8alone.median()

edited_median = df_edited.median()

ut_median = df_ut.median()
```

```python
edited_median

```

```python
ut_median
```

**Plotting in sets of 10, a bit hard to compare edited (top) vs. unedited (bottom) as scales are different, scroll down to find side-by-side same scale plots.**

```python
# First 10
df_edited.iloc[:, :10].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
df_ut.iloc[:, :10].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
```

```python
# 11-20
df_edited.iloc[:, 11:20].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
df_ut.iloc[:, 11:20].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
```

```python
# 21-30
df_edited.iloc[:, 21:30].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
df_ut.iloc[:, 21:30].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
```

```python
# 31-40
df_edited.iloc[:, 31:40].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
df_ut.iloc[:, 31:40].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
```

```python
# 41-50
df_edited.iloc[:, 41:50].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
df_ut.iloc[:, 41:50].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
```

```python
# 51-60
df_edited.iloc[:, 51:60].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
df_ut.iloc[:, 51:60].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
```

```python
# 61-70
df_edited.iloc[:, 61:70].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
df_ut.iloc[:, 61:70].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
```

```python
# 71-80
df_edited.iloc[:, 71:80].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
df_ut.iloc[:, 71:80].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
```

```python
# 81-90
df_edited.iloc[:, 81:90].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
df_ut.iloc[:, 81:90].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
```

```python
# 91-100
df_edited.iloc[:, 91:100].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
df_ut.iloc[:, 91:100].boxplot()
plt.title('Boxplots of All Columns')
plt.ylabel('Values')
plt.xticks(rotation=45)  # Rotate x labels for better visibility
plt.show()
```

```python

for i in range(100):
  combined_df = pd.concat([df_edited.iloc[:, i:i+1], df_ut.iloc[:, i:i+1]], axis=1)

  # Create side-by-side boxplots
  combined_df.boxplot()
  plt.title('Edited (Left) vs. Unedited (Right) #' + str(i+1))
  plt.ylabel('Values')
  plt.xticks(rotation=45)  # Rotate x labels for better visibility
  plt.show()
```

**Plots that looked most interesting:**




**4**

**5**

**12**

**18**

**29**

**34**

**38**

**41**

**43**

**44**

**45**

**55**

**63**

**64**

**68**

**77**

**78**

**81**










### File: Code/EDA/pca.ipynb
# Jupyter Notebook Conversion
# Basic Data Transformation (for editing mechanism and edited/unedited status)

(hard-coded)

```python
import pandas as pd
from sklearn.preprocessing import StandardScaler

# Load the dataset
df = pd.read_csv('../../data/GSE218462_raw_counts_GRCh38.p13_NCBI.tsv', sep='\t')
df = df.T
df.columns = df.iloc[0]
df = df[1:]

scaler = StandardScaler()
scaled_data = scaler.fit_transform(df)
scaled_df = pd.DataFrame(scaled_data)

scaled_df.columns = df.columns
scaled_df.index = df.index
unedited = ['GSM6745632', 'GSM6745633', 'GSM6745634', 'GSM6745635', 'GSM6745636', 'GSM6745637']
scaled_df['Edited (1) or Unedited (0)'] = scaled_df.index.map(lambda gene: 0 if gene in unedited else 1)
mechanisms = {
    "BE4": ["GSM6745599", "GSM6745600", "GSM6745601", "GSM6745611", "GSM6745612", "GSM6745613"],
    "ABE8": ["GSM6745602", "GSM6745603", "GSM6745604", "GSM6745614", "GSM6745615", "GSM6745616"],
    "Cas9": ["GSM6745605", "GSM6745606", "GSM6745607", "GSM6745617", "GSM6745618", "GSM6745619"],
    "Utelectro": ["GSM6745608", "GSM6745609", "GSM6745610", "GSM6745620", "GSM6745621", "GSM6745622"],
    "dCas9": ["GSM6745623", "GSM6745624", "GSM6745625"],
    "BE4alone": ["GSM6745626", "GSM6745627", "GSM6745628"],
    "ABE8alone": ["GSM6745629", "GSM6745630", "GSM6745631"],
    "UT": ["GSM6745632", "GSM6745633", "GSM6745634", "GSM6745635", "GSM6745636", "GSM6745637"]
}

# Inverting the dictionary to map gene code to its corresponding key
mechanism_map = {gene: mechanism for mechanism, genes in mechanisms.items() for gene in genes}

# Adding a new column "editing mechanism" to categorize the gene codes in the index
scaled_df['editing mechanism'] = scaled_df.index.map(mechanism_map)

scaled_df
```

```python
scaled_df['editing mechanism']
```

# PCA

```python
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

pca_df = scaled_df.drop(columns=['Edited (1) or Unedited (0)', 'editing mechanism'])

pca = PCA(n_components=5)

principalComponents = pca.fit_transform(pca_df)

principalDf = pd.DataFrame(data = principalComponents, columns = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5'])

# Plot the PCA result
plt.scatter(principalDf['PC1'], principalDf['PC2'])
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.title('PCA of Gene Expression Data')
plt.show()

plt.scatter(principalDf['PC1'], principalDf['PC3'])
plt.xlabel('PC1')
plt.ylabel('PC2')
plt.title('PCA of Gene Expression Data')
plt.show()
```

```python
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

# Perform PCA
pca_df = scaled_df.drop(columns=['Edited (1) or Unedited (0)', 'editing mechanism'])
target1 = scaled_df['Edited (1) or Unedited (0)']
target2 = scaled_df['editing mechanism']
pca = PCA()
pca_result = pca.fit_transform(pca_df)

# Calculate the cumulative explained variance ratio
cumulative_variance_ratio = np.cumsum(pca.explained_variance_ratio_)

# Plot the cumulative explained variance ratio
plt.plot(range(1, len(cumulative_variance_ratio) + 1), cumulative_variance_ratio)
plt.xlabel('Number of Components')
plt.ylabel('Cumulative Explained Variance Ratio')
plt.title('Explained Variance Ratio vs. Number of Components')
plt.show()
```

```python
# Find the number of components that explain 95% of the variance
n_components_99 = np.argmax(cumulative_variance_ratio >= 0.99) + 1
print(f"Number of components explaining 99% of variance: {n_components_99}")

n_components_95 = np.argmax(cumulative_variance_ratio >= 0.95) + 1
print(f"Number of components explaining 95% of variance: {n_components_95}")

n_components_90 = np.argmax(cumulative_variance_ratio >= 0.90) + 1
print(f"Number of components explaining 90% of variance: {n_components_90}")

n_components_85 = np.argmax(cumulative_variance_ratio >= 0.85) + 1
print(f"Number of components explaining 85% of variance: {n_components_85}")

n_components_80 = np.argmax(cumulative_variance_ratio >= 0.80) + 1
print(f"Number of components explaining 80% of variance: {n_components_80}")

n_components_75 = np.argmax(cumulative_variance_ratio >= 0.75) + 1
print(f"Number of components explaining 75% of variance: {n_components_75}")
```

will move on from PCA1 and 2, kept trying to analyze the PCA with PCA1 and PCA2 that's used later, but it didn't come up with anything interesting, probably because I missed this part where the variance is explained by 36%~ things... let's check this

~ IMT

Function below for easier tweaking:

```python
def num_components(num):
    n_components = np.argmax(cumulative_variance_ratio >= num) + 1
    return n_components
```

```python
# Perform PCA with the selected number of components
pca_final = PCA(n_components=n_components_75)
pca_result_final = pca_final.fit_transform(pca_df)
```

```python
# Create a new dataframe with the reduced number of genes
columns = [f'PC{i+1}' for i in range(pca_result_final.shape[1])]
df_pca = pd.DataFrame(data=pca_result_final, columns=columns, index=pca_df.index)

# Add back the target variable if needed
df_pca['Edited or unedited'] = target1.values
df_pca['Editing mechanism'] = target2.values

df_pca
```

```python
# Assuming we've already performed the PCA as in the previous steps
# and we have pca_final, pca_result_final, and df_pca

# Plot 1: Explained Variance Ratio
plt.figure(figsize=(10, 5))
plt.bar(range(1, len(pca_final.explained_variance_ratio_) + 1), pca_final.explained_variance_ratio_)
plt.xlabel('Principal Component')
plt.ylabel('Explained Variance Ratio')
plt.title('Explained Variance Ratio by Principal Component')
plt.tight_layout()
plt.show()

# Plot 2: Data points in PC1 vs PC2 space
plt.figure(figsize=(10, 8))
scatter = plt.scatter(df_pca['PC1'], df_pca['PC2'], c=df_pca['Edited or unedited'], cmap='viridis', alpha=0.7)
plt.xlabel('First Principal Component')
plt.ylabel('Second Principal Component')
plt.title('Data points in PC1 vs PC2 space')
plt.colorbar(scatter, label='Edited (1) or Unedited (0)')
plt.tight_layout()
plt.show()
```

Extracting which genes are most significant (if we stick with 2 principal components, can be modified later on)

```python
# Print shapes for verification
print("Shape of pca_final.components_:", pca_final.components_.shape)
print("Shape of pca_df:", pca_df.shape)

# Get the correct gene IDs (should be 39376 of them)
gene_ids = pca_df.columns  # This should be the correct gene IDs

print("Number of gene IDs:", len(gene_ids))

# Create a DataFrame of the PCA components
components_df = pd.DataFrame(
    pca_final.components_,  # No need to transpose, it's already in the correct orientation
    columns=gene_ids,
    index=[f'PC{i+1}' for i in range(pca_final.n_components_)]
)

# Transpose components_df so that genes are rows and PCs are columns
components_df = components_df.T

# Function to get top contributing genes for a given PC
def get_top_genes(pc_number, n=3):
    pc = components_df[f'PC{pc_number}']
    top_positive = pc.nlargest(n)
    top_negative = pc.nsmallest(n)
    return pd.concat([top_positive, top_negative])
    #top_genes = pc.abs().nlargest(n)  # Get top n by magnitude
    #return top_genes

# Get top contributing genes for first 2 pc's
for i in range(1, 3):
    print(f"\nTop contributing genes for PC{i}:")
    print(get_top_genes(i))

# Calculate the overall importance of each gene across all PCs
gene_importance = np.sum(components_df**2, axis=1)
top_genes = gene_importance.nlargest(20)

print("\nTop 20 most important genes overall:")
print(top_genes)

# Print final shapes to verify
print("\nFinal shape of components_df:", components_df.shape)
```



### File: Code/EDA_sj/LifeEdit_EDA_SJ.ipynb
# Jupyter Notebook Conversion
<a href="https://colab.research.google.com/github/IslamTayeb/life-edit-gene-classifier/blob/main/LifeEdit_EDA_SJ.ipynb" target="_parent"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>

```python
!pip install -U kaleido
```

```python
%matplotlib inline
```

```python
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
```

```python
raw_df1 = pd.read_csv("/content/GSE218462_raw_counts_GRCh38.p13_NCBI.tsv", sep = '\t')
```

```python
raw_df1
```

```python
genes = raw_df1["GeneID"]
samples = raw_df1.columns
```

```python
samples
```

```python
raw_df1_T = raw_df1.T
raw_df1_T
```

```python
raw_df1_T.columns = raw_df1_T.iloc[0]
raw_df1_T = raw_df1_T[1:]
```

```python
raw_df1_T
```

```python
scaler = StandardScaler()
scaled_data1 = scaler.fit_transform(raw_df1_T)
```

```python
scaled_df1 = pd.DataFrame(scaled_data1)
scaled_df1
```

```python
scaled_df1.columns = raw_df1_T.columns
scaled_df1.index = raw_df1_T.index
```

```python
scaled_df1
```

**EDA using scaled_df1**

```python
scaled_df1
```

```python
scaled_df1.info()
```

```python